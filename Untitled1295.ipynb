{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "accf957b-8bb5-466c-9aca-7d735fddb40c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sagni\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\PIL\\Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] train/real: 326 images\n",
      "[INFO] train/fake: 153 images\n",
      "[INFO] sample/fake: 5 images\n",
      "[INFO] test/fake: 389 images\n",
      "[INFO] test/real: 110 images\n",
      "[INFO] Total rows: 983\n",
      "[SAVED] Features CSV -> C:\\Users\\sagni\\Downloads\\DeepFakeShield\\deepfakeshield_features.csv\n",
      "[SAVED] Feature correlation heatmap -> C:\\Users\\sagni\\Downloads\\DeepFakeShield\\deepfakeshield_feature_corr_heatmap.png\n",
      "[SAVED] Accuracy graph -> C:\\Users\\sagni\\Downloads\\DeepFakeShield\\deepfakeshield_accuracy_over_epochs.png\n",
      "[SAVED] Accuracy CSV -> C:\\Users\\sagni\\Downloads\\DeepFakeShield\\deepfakeshield_accuracy_over_epochs.csv\n",
      "[SAVED] Confusion matrix heatmap -> C:\\Users\\sagni\\Downloads\\DeepFakeShield\\deepfakeshield_confusion_heatmap.png\n",
      "[SAVED] Classification report -> C:\\Users\\sagni\\Downloads\\DeepFakeShield\\deepfakeshield_classification_report.txt\n",
      "\n",
      "[DONE] Outputs in: C:\\Users\\sagni\\Downloads\\DeepFakeShield\n",
      " - C:\\Users\\sagni\\Downloads\\DeepFakeShield\\deepfakeshield_features.csv\n",
      " - C:\\Users\\sagni\\Downloads\\DeepFakeShield\\deepfakeshield_feature_corr_heatmap.png\n",
      " - C:\\Users\\sagni\\Downloads\\DeepFakeShield\\deepfakeshield_accuracy_over_epochs.png\n",
      " - C:\\Users\\sagni\\Downloads\\DeepFakeShield\\deepfakeshield_accuracy_over_epochs.csv\n",
      " - C:\\Users\\sagni\\Downloads\\DeepFakeShield\\deepfakeshield_confusion_heatmap.png\n",
      " - C:\\Users\\sagni\\Downloads\\DeepFakeShield\\deepfakeshield_classification_report.txt\n"
     ]
    }
   ],
   "source": [
    "# ==========================================================\n",
    "# DeepFakeShield â€” Accuracy Graph + Heatmaps (Full Script)\n",
    "# ==========================================================\n",
    "# Inputs (recursive):\n",
    "#   Train/Real:\n",
    "#     C:\\Users\\sagni\\Downloads\\DeepFakeShield\\archive\\train-20250112T065955Z-001\\train\\real\n",
    "#   Train/Fake:\n",
    "#     C:\\Users\\sagni\\Downloads\\DeepFakeShield\\archive\\train-20250112T065955Z-001\\train\\fake\n",
    "#   Sample/Fake:\n",
    "#     C:\\Users\\sagni\\Downloads\\DeepFakeShield\\archive\\Sample_fake_images\\Sample_fake_images\\fake\n",
    "#   Test/Fake:\n",
    "#     C:\\Users\\sagni\\Downloads\\DeepFakeShield\\archive\\test-20250112T065939Z-001\\test\\fake\n",
    "#   Test/Real:\n",
    "#     C:\\Users\\sagni\\Downloads\\DeepFakeShield\\archive\\test-20250112T065939Z-001\\test\\real\n",
    "#\n",
    "# Outputs (saved to C:\\Users\\sagni\\Downloads\\DeepFakeShield):\n",
    "#   - deepfakeshield_features.csv\n",
    "#   - deepfakeshield_feature_corr_heatmap.png\n",
    "#   - deepfakeshield_confusion_heatmap.png\n",
    "#   - deepfakeshield_accuracy_over_epochs.png\n",
    "#   - deepfakeshield_accuracy_over_epochs.csv\n",
    "# ==========================================================\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any, Tuple\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.feature import canny\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, confusion_matrix, classification_report\n",
    ")\n",
    "\n",
    "# ----------------------------\n",
    "# Paths / Config\n",
    "# ----------------------------\n",
    "OUT_DIR = Path(r\"C:\\Users\\sagni\\Downloads\\DeepFakeShield\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "DIRS: List[Tuple[Path, str, str]] = [\n",
    "    (Path(r\"C:\\Users\\sagni\\Downloads\\DeepFakeShield\\archive\\train-20250112T065955Z-001\\train\\real\"), \"train\", \"real\"),\n",
    "    (Path(r\"C:\\Users\\sagni\\Downloads\\DeepFakeShield\\archive\\train-20250112T065955Z-001\\train\\fake\"), \"train\", \"fake\"),\n",
    "    (Path(r\"C:\\Users\\sagni\\Downloads\\DeepFakeShield\\archive\\Sample_fake_images\\Sample_fake_images\\fake\"), \"sample\", \"fake\"),\n",
    "    (Path(r\"C:\\Users\\sagni\\Downloads\\DeepFakeShield\\archive\\test-20250112T065939Z-001\\test\\fake\"), \"test\", \"fake\"),\n",
    "    (Path(r\"C:\\Users\\sagni\\Downloads\\DeepFakeShield\\archive\\test-20250112T065939Z-001\\test\\real\"), \"test\", \"real\"),\n",
    "]\n",
    "\n",
    "IMG_EXTS = {\".jpg\", \".jpeg\", \".png\", \".tif\", \".tiff\", \".bmp\", \".webp\", \".gif\"}\n",
    "\n",
    "FEATURES_CSV = OUT_DIR / \"deepfakeshield_features.csv\"\n",
    "CORR_PNG     = OUT_DIR / \"deepfakeshield_feature_corr_heatmap.png\"\n",
    "CM_PNG       = OUT_DIR / \"deepfakeshield_confusion_heatmap.png\"\n",
    "ACC_PNG      = OUT_DIR / \"deepfakeshield_accuracy_over_epochs.png\"\n",
    "ACC_CSV      = OUT_DIR / \"deepfakeshield_accuracy_over_epochs.csv\"\n",
    "REPORT_TXT   = OUT_DIR / \"deepfakeshield_classification_report.txt\"\n",
    "\n",
    "# ----------------------------\n",
    "# Utilities\n",
    "# ----------------------------\n",
    "def list_images(root: Path) -> List[Path]:\n",
    "    if not root.exists():\n",
    "        print(f\"[WARN] Missing directory (skipped): {root}\")\n",
    "        return []\n",
    "    return [p for p in root.rglob(\"*\") if p.is_file() and p.suffix.lower() in IMG_EXTS]\n",
    "\n",
    "def extract_features_one(path: Path, hist_bins: int = 16, edge_resize: int = 256) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Extract numeric features:\n",
    "      - width/height/aspect_ratio\n",
    "      - RGB mean/std\n",
    "      - grayscale brightness & contrast\n",
    "      - edge density (Canny on resized gray)\n",
    "      - grayscale histogram (L1-normalized, 'hist_00'..'hist_15')\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with Image.open(path) as im:\n",
    "            im = im.convert(\"RGB\")\n",
    "            w, h = im.size\n",
    "            arr = np.asarray(im, dtype=np.float32) / 255.0  # HxWx3 in [0,1]\n",
    "\n",
    "        width, height = float(w), float(h)\n",
    "        aspect = float(w / h) if h else np.nan\n",
    "\n",
    "        r, g, b = arr[..., 0], arr[..., 1], arr[..., 2]\n",
    "        mean_r, mean_g, mean_b = float(r.mean()), float(g.mean()), float(b.mean())\n",
    "        std_r,  std_g,  std_b  = float(r.std()),  float(g.std()),  float(b.std())\n",
    "\n",
    "        gray = rgb2gray(arr)  # [0,1]\n",
    "        brightness = float(gray.mean())\n",
    "        contrast   = float(gray.std())\n",
    "\n",
    "        # Edge density on resized gray (keep aspect ratio)\n",
    "        if min(h, w) > 0 and min(h, w) != edge_resize:\n",
    "            scale = edge_resize / min(h, w)\n",
    "            new_w, new_h = int(w * scale), int(h * scale)\n",
    "            gray_small = np.asarray(Image.fromarray((gray*255).astype(np.uint8)).resize((new_w, new_h))) / 255.0\n",
    "        else:\n",
    "            gray_small = gray\n",
    "        edges = canny(gray_small, sigma=1.5)\n",
    "        edge_density = float(edges.mean())\n",
    "\n",
    "        # Grayscale histogram\n",
    "        hist, _ = np.histogram((gray*255.0).astype(np.uint8), bins=hist_bins, range=(0, 255))\n",
    "        hist = hist.astype(np.float32)\n",
    "        hist = hist / (hist.sum() + 1e-9)\n",
    "\n",
    "        feats = {\n",
    "            \"width\": width, \"height\": height, \"aspect_ratio\": aspect,\n",
    "            \"mean_r\": mean_r, \"mean_g\": mean_g, \"mean_b\": mean_b,\n",
    "            \"std_r\": std_r, \"std_g\": std_g, \"std_b\": std_b,\n",
    "            \"brightness\": brightness, \"contrast\": contrast,\n",
    "            \"edge_density\": edge_density,\n",
    "        }\n",
    "        for i, v in enumerate(hist):\n",
    "            feats[f\"hist_{i:02d}\"] = float(v)\n",
    "        return feats\n",
    "\n",
    "    except Exception as e:\n",
    "        # Return NaNs so row can be dropped later\n",
    "        base = {\n",
    "            \"width\": np.nan, \"height\": np.nan, \"aspect_ratio\": np.nan,\n",
    "            \"mean_r\": np.nan, \"mean_g\": np.nan, \"mean_b\": np.nan,\n",
    "            \"std_r\": np.nan, \"std_g\": np.nan, \"std_b\": np.nan,\n",
    "            \"brightness\": np.nan, \"contrast\": np.nan,\n",
    "            \"edge_density\": np.nan,\n",
    "        }\n",
    "        for i in range(16):\n",
    "            base[f\"hist_{i:02d}\"] = np.nan\n",
    "        base[\"error\"] = str(e)\n",
    "        return base\n",
    "\n",
    "def scan_dirs(dirs: List[Tuple[Path, str, str]]) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    for root, split, label_name in dirs:\n",
    "        label = 1 if label_name.lower() == \"fake\" else 0\n",
    "        files = list_images(root)\n",
    "        for p in files:\n",
    "            feats = extract_features_one(p)\n",
    "            row = {\n",
    "                \"split\": split,\n",
    "                \"label_name\": label_name,\n",
    "                \"label\": label,\n",
    "                \"filename\": p.name,\n",
    "                \"relpath\": str(p.relative_to(root)),\n",
    "                \"abspath\": str(p.resolve()),\n",
    "                **feats\n",
    "            }\n",
    "            rows.append(row)\n",
    "        print(f\"[INFO] {split}/{label_name}: {len(files)} images\")\n",
    "    df = pd.DataFrame(rows)\n",
    "    if not df.empty:\n",
    "        df = df.sort_values([\"split\", \"label_name\", \"filename\"]).reset_index(drop=True)\n",
    "    print(f\"[INFO] Total rows: {len(df)}\")\n",
    "    return df\n",
    "\n",
    "def plot_confusion_heatmap(cm: np.ndarray, labels: list, title: str, out_path: Path):\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    im = plt.imshow(cm, aspect='equal')\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"True\")\n",
    "    plt.colorbar(im)\n",
    "    plt.xticks(range(len(labels)), labels)\n",
    "    plt.yticks(range(len(labels)), labels)\n",
    "    for (i, j), v in np.ndenumerate(cm):\n",
    "        plt.text(j, i, str(v), ha='center', va='center')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_path, dpi=220)\n",
    "    plt.close()\n",
    "\n",
    "# ----------------------------\n",
    "# 1) Build feature table\n",
    "# ----------------------------\n",
    "df = scan_dirs(DIRS)\n",
    "if df.empty:\n",
    "    raise SystemExit(\"No images found. Please check your paths.\")\n",
    "\n",
    "# Drop rows with missing core features\n",
    "core = [\"width\", \"height\", \"aspect_ratio\", \"brightness\", \"contrast\", \"edge_density\"]\n",
    "df_clean = df.dropna(subset=core).reset_index(drop=True)\n",
    "df_clean.to_csv(FEATURES_CSV, index=False)\n",
    "print(f\"[SAVED] Features CSV -> {FEATURES_CSV}\")\n",
    "\n",
    "# ----------------------------\n",
    "# 2) Feature correlation heatmap (all splits together)\n",
    "# ----------------------------\n",
    "feat_cols = [c for c in df_clean.columns\n",
    "             if c not in {\"split\",\"label_name\",\"label\",\"filename\",\"relpath\",\"abspath\",\"error\"}]\n",
    "feat_cols = [c for c in feat_cols if pd.api.types.is_numeric_dtype(df_clean[c])]\n",
    "corr = df_clean[feat_cols].corr(numeric_only=True)\n",
    "\n",
    "plt.figure(figsize=(12, 9))\n",
    "im = plt.imshow(corr.values, aspect='auto')\n",
    "plt.xticks(range(corr.shape[1]), corr.columns, rotation=45, ha='right', fontsize=8)\n",
    "plt.yticks(range(corr.shape[0]), corr.index, fontsize=8)\n",
    "plt.title(\"DeepFakeShield: Feature Correlation Heatmap\")\n",
    "plt.colorbar(im)\n",
    "plt.tight_layout()\n",
    "plt.savefig(CORR_PNG, dpi=220)\n",
    "plt.close()\n",
    "print(f\"[SAVED] Feature correlation heatmap -> {CORR_PNG}\")\n",
    "\n",
    "# ----------------------------\n",
    "# 3) Train (train split) / Test (test + sample)\n",
    "# ----------------------------\n",
    "train_df = df_clean[df_clean[\"split\"] == \"train\"].copy()\n",
    "test_df  = df_clean[df_clean[\"split\"].isin([\"test\",\"sample\"])].copy()\n",
    "\n",
    "if train_df.empty or test_df.empty:\n",
    "    raise SystemExit(\"Train or Test split is empty. Ensure your folders have images.\")\n",
    "\n",
    "X_train = train_df[feat_cols].astype(float).values\n",
    "y_train = train_df[\"label\"].astype(int).values\n",
    "\n",
    "X_test  = test_df[feat_cols].astype(float).values\n",
    "y_test  = test_df[\"label\"].astype(int).values\n",
    "\n",
    "# Standardize\n",
    "scaler = StandardScaler()\n",
    "X_train_sc = scaler.fit_transform(X_train)\n",
    "X_test_sc  = scaler.transform(X_test)\n",
    "\n",
    "# ----------------------------\n",
    "# 4) Accuracy over epochs (SGD logistic)\n",
    "# ----------------------------\n",
    "clf = SGDClassifier(\n",
    "    loss=\"log_loss\",\n",
    "    alpha=1e-4,\n",
    "    max_iter=1,     # we'll loop epochs manually\n",
    "    learning_rate=\"optimal\",\n",
    "    random_state=42,\n",
    "    warm_start=True\n",
    ")\n",
    "classes = np.unique(y_train)\n",
    "epochs = 15\n",
    "train_acc, test_acc = [], []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    if epoch == 0:\n",
    "        clf.partial_fit(X_train_sc, y_train, classes=classes)\n",
    "    else:\n",
    "        clf.partial_fit(X_train_sc, y_train)\n",
    "\n",
    "    yhat_tr = clf.predict(X_train_sc)\n",
    "    yhat_te = clf.predict(X_test_sc)\n",
    "\n",
    "    train_acc.append(accuracy_score(y_train, yhat_tr))\n",
    "    test_acc.append(accuracy_score(y_test, yhat_te))\n",
    "\n",
    "# Plot accuracy curve\n",
    "plt.figure(figsize=(8, 4.5))\n",
    "plt.plot(range(1, epochs+1), train_acc, marker='o', label=\"Train Accuracy\")\n",
    "plt.plot(range(1, epochs+1), test_acc, marker='s', label=\"Test Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"DeepFakeShield: Accuracy over Epochs (SGD Logistic)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig(ACC_PNG, dpi=220)\n",
    "plt.close()\n",
    "print(f\"[SAVED] Accuracy graph -> {ACC_PNG}\")\n",
    "\n",
    "# Save accuracy CSV\n",
    "pd.DataFrame({\n",
    "    \"epoch\": list(range(1, epochs+1)),\n",
    "    \"train_accuracy\": train_acc,\n",
    "    \"test_accuracy\": test_acc\n",
    "}).to_csv(ACC_CSV, index=False)\n",
    "print(f\"[SAVED] Accuracy CSV -> {ACC_CSV}\")\n",
    "\n",
    "# ----------------------------\n",
    "# 5) Final evaluation (balanced Logistic Regression) + Confusion heatmap\n",
    "# ----------------------------\n",
    "final_lr = LogisticRegression(\n",
    "    solver=\"saga\",\n",
    "    penalty=\"l2\",\n",
    "    class_weight=\"balanced\",\n",
    "    max_iter=600,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "final_lr.fit(X_train_sc, y_train)\n",
    "y_pred = final_lr.predict(X_test_sc)\n",
    "cm = confusion_matrix(y_test, y_pred, labels=[0,1])\n",
    "plot_confusion_heatmap(\n",
    "    cm, labels=[\"Real (0)\", \"Fake (1)\"],\n",
    "    title=\"DeepFakeShield: Confusion Matrix (Balanced LR)\",\n",
    "    out_path=CM_PNG\n",
    ")\n",
    "print(f\"[SAVED] Confusion matrix heatmap -> {CM_PNG}\")\n",
    "\n",
    "report = classification_report(y_test, y_pred, digits=4)\n",
    "with open(REPORT_TXT, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"=== DeepFakeShield: Balanced Logistic Regression (Test) ===\\n\\n\")\n",
    "    f.write(report + \"\\n\")\n",
    "print(f\"[SAVED] Classification report -> {REPORT_TXT}\")\n",
    "\n",
    "print(\"\\n[DONE] Outputs in:\", OUT_DIR)\n",
    "print(\" -\", FEATURES_CSV)\n",
    "print(\" -\", CORR_PNG)\n",
    "print(\" -\", ACC_PNG)\n",
    "print(\" -\", ACC_CSV)\n",
    "print(\" -\", CM_PNG)\n",
    "print(\" -\", REPORT_TXT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253b1087-8d8e-4e82-b8f2-9469d7b4fa14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (moviepy)",
   "language": "python",
   "name": "py311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
