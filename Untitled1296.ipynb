{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ebbeb687-2840-410e-9467-8d1f7c5fbf80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sagni\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\PIL\\Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] train | label=0: 326 images from C:\\Users\\sagni\\Downloads\\DeepFakeShield\\archive\\train-20250112T065955Z-001\\train\\real\n",
      "[INFO] train | label=1: 153 images from C:\\Users\\sagni\\Downloads\\DeepFakeShield\\archive\\train-20250112T065955Z-001\\train\\fake\n",
      "[INFO] test | label=0: 110 images from C:\\Users\\sagni\\Downloads\\DeepFakeShield\\archive\\test-20250112T065939Z-001\\test\\real\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sagni\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\PIL\\Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] test | label=1: 389 images from C:\\Users\\sagni\\Downloads\\DeepFakeShield\\archive\\test-20250112T065939Z-001\\test\\fake\n",
      "[INFO] sample | label=1: 5 images from C:\\Users\\sagni\\Downloads\\DeepFakeShield\\archive\\Sample_fake_images\\Sample_fake_images\\fake\n",
      "[INFO] Training model...\n",
      "[SAVED] Test predictions -> C:\\Users\\sagni\\Downloads\\DeepFakeShield\\deepfakeshield_test_predictions.csv\n",
      "[SAVED] Sample predictions -> C:\\Users\\sagni\\Downloads\\DeepFakeShield\\deepfakeshield_sample_predictions.csv\n",
      "[INFO] Test ROC-AUC: 0.7170 | PR-AUC: 0.8948\n",
      "[INFO] Confusion matrix:\n",
      " [[ 70  40]\n",
      " [132 257]]\n",
      "[INFO] Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.3465    0.6364    0.4487       110\n",
      "           1     0.8653    0.6607    0.7493       389\n",
      "\n",
      "    accuracy                         0.6553       499\n",
      "   macro avg     0.6059    0.6485    0.5990       499\n",
      "weighted avg     0.7510    0.6553    0.6830       499\n",
      "\n",
      "[SAVED] Metrics JSON -> C:\\Users\\sagni\\Downloads\\DeepFakeShield\\deepfakeshield_metrics.json\n",
      "[SAVED] Classification report -> C:\\Users\\sagni\\Downloads\\DeepFakeShield\\deepfakeshield_classification_report.txt\n",
      "[SAVED] ROC curve -> C:\\Users\\sagni\\Downloads\\DeepFakeShield\\deepfakeshield_roc_curve.png\n",
      "[SAVED] PR curve -> C:\\Users\\sagni\\Downloads\\DeepFakeShield\\deepfakeshield_pr_curve.png\n",
      "[SAVED] Confusion matrix -> C:\\Users\\sagni\\Downloads\\DeepFakeShield\\deepfakeshield_confusion_matrix.png\n",
      "[SAVED] Feature importance -> C:\\Users\\sagni\\Downloads\\DeepFakeShield\\deepfakeshield_feature_importance.csv\n",
      "[SAVED] Model -> C:\\Users\\sagni\\Downloads\\DeepFakeShield\\deepfakeshield_model.pkl\n",
      "\n",
      "[DONE] All artifacts saved in: C:\\Users\\sagni\\Downloads\\DeepFakeShield\n"
     ]
    }
   ],
   "source": [
    "# ==========================================================\n",
    "# DeepFakeShield â€” Train & Predict (Full Script)\n",
    "# ==========================================================\n",
    "# Inputs (recursive):\n",
    "#   Train/Real:\n",
    "#     C:\\Users\\sagni\\Downloads\\DeepFakeShield\\archive\\train-20250112T065955Z-001\\train\\real\n",
    "#   Train/Fake:\n",
    "#     C:\\Users\\sagni\\Downloads\\DeepFakeShield\\archive\\train-20250112T065955Z-001\\train\\fake\n",
    "#   Sample/Fake (optional extra test set):\n",
    "#     C:\\Users\\sagni\\Downloads\\DeepFakeShield\\archive\\Sample_fake_images\\Sample_fake_images\\fake\n",
    "#   Test/Fake:\n",
    "#     C:\\Users\\sagni\\Downloads\\DeepFakeShield\\archive\\test-20250112T065939Z-001\\test\\fake\n",
    "#   Test/Real:\n",
    "#     C:\\Users\\sagni\\Downloads\\DeepFakeShield\\archive\\test-20250112T065939Z-001\\test\\real\n",
    "#\n",
    "# Outputs (saved to C:\\Users\\sagni\\Downloads\\DeepFakeShield):\n",
    "#   - deepfakeshield_model.pkl\n",
    "#   - deepfakeshield_test_predictions.csv\n",
    "#   - deepfakeshield_sample_predictions.csv   (if sample set found)\n",
    "#   - deepfakeshield_metrics.json             (for test set)\n",
    "#   - deepfakeshield_confusion_matrix.png\n",
    "#   - deepfakeshield_roc_curve.png\n",
    "#   - deepfakeshield_pr_curve.png\n",
    "#   - deepfakeshield_feature_importance.csv\n",
    "#   - deepfakeshield_classification_report.txt\n",
    "# ==========================================================\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any, Tuple\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.feature import canny\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, average_precision_score,\n",
    "    precision_recall_curve, roc_curve,\n",
    "    confusion_matrix, classification_report\n",
    ")\n",
    "import joblib\n",
    "\n",
    "# ----------------------------\n",
    "# Paths / Config\n",
    "# ----------------------------\n",
    "OUT_DIR = Path(r\"C:\\Users\\sagni\\Downloads\\DeepFakeShield\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "TRAIN_REAL = Path(r\"C:\\Users\\sagni\\Downloads\\DeepFakeShield\\archive\\train-20250112T065955Z-001\\train\\real\")\n",
    "TRAIN_FAKE = Path(r\"C:\\Users\\sagni\\Downloads\\DeepFakeShield\\archive\\train-20250112T065955Z-001\\train\\fake\")\n",
    "TEST_FAKE  = Path(r\"C:\\Users\\sagni\\Downloads\\DeepFakeShield\\archive\\test-20250112T065939Z-001\\test\\fake\")\n",
    "TEST_REAL  = Path(r\"C:\\Users\\sagni\\Downloads\\DeepFakeShield\\archive\\test-20250112T065939Z-001\\test\\real\")\n",
    "SAMPLE_FAKE = Path(r\"C:\\Users\\sagni\\Downloads\\DeepFakeShield\\archive\\Sample_fake_images\\Sample_fake_images\\fake\")  # optional\n",
    "\n",
    "IMG_EXTS = {\".jpg\", \".jpeg\", \".png\", \".tif\", \".tiff\", \".bmp\", \".webp\", \".gif\"}\n",
    "HIST_BINS = 16            # grayscale histogram bins\n",
    "EDGE_RESIZE = 256         # resize shorter side for edge density\n",
    "THRESHOLD = 0.5           # decision threshold on probability\n",
    "\n",
    "# Output artifact paths\n",
    "MODEL_PKL = OUT_DIR / \"deepfakeshield_model.pkl\"\n",
    "TEST_PRED_CSV = OUT_DIR / \"deepfakeshield_test_predictions.csv\"\n",
    "SAMPLE_PRED_CSV = OUT_DIR / \"deepfakeshield_sample_predictions.csv\"\n",
    "METRICS_JSON = OUT_DIR / \"deepfakeshield_metrics.json\"\n",
    "CM_PNG = OUT_DIR / \"deepfakeshield_confusion_matrix.png\"\n",
    "ROC_PNG = OUT_DIR / \"deepfakeshield_roc_curve.png\"\n",
    "PR_PNG = OUT_DIR / \"deepfakeshield_pr_curve.png\"\n",
    "FI_CSV = OUT_DIR / \"deepfakeshield_feature_importance.csv\"\n",
    "CLS_TXT = OUT_DIR / \"deepfakeshield_classification_report.txt\"\n",
    "\n",
    "# ----------------------------\n",
    "# Utilities\n",
    "# ----------------------------\n",
    "def list_images(root: Path) -> List[Path]:\n",
    "    if not root.exists():\n",
    "        print(f\"[WARN] Missing: {root}\")\n",
    "        return []\n",
    "    return [p for p in root.rglob(\"*\") if p.is_file() and p.suffix.lower() in IMG_EXTS]\n",
    "\n",
    "def extract_features_one(path: Path, hist_bins: int = HIST_BINS, edge_resize: int = EDGE_RESIZE) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Lightweight vision features:\n",
    "      - width/height/aspect_ratio\n",
    "      - RGB mean/std\n",
    "      - grayscale brightness & contrast\n",
    "      - edge density (Canny on resized gray)\n",
    "      - grayscale histogram (hist_bins, L1-normalized)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with Image.open(path) as im:\n",
    "            im = im.convert(\"RGB\")\n",
    "            w, h = im.size\n",
    "            arr = np.asarray(im, dtype=np.float32) / 255.0\n",
    "        width, height = float(w), float(h)\n",
    "        aspect = float(w / h) if h else np.nan\n",
    "\n",
    "        r, g, b = arr[..., 0], arr[..., 1], arr[..., 2]\n",
    "        mean_r, mean_g, mean_b = float(r.mean()), float(g.mean()), float(b.mean())\n",
    "        std_r,  std_g,  std_b  = float(r.std()),  float(g.std()),  float(b.std())\n",
    "\n",
    "        gray = rgb2gray(arr)  # [0,1]\n",
    "        brightness = float(gray.mean())\n",
    "        contrast   = float(gray.std())\n",
    "\n",
    "        # Edge density on resized gray\n",
    "        if min(h, w) > 0 and min(h, w) != edge_resize:\n",
    "            scale = edge_resize / min(h, w)\n",
    "            new_w, new_h = int(w * scale), int(h * scale)\n",
    "            gray_small = np.asarray(Image.fromarray((gray*255).astype(np.uint8)).resize((new_w, new_h))) / 255.0\n",
    "        else:\n",
    "            gray_small = gray\n",
    "        edges = canny(gray_small, sigma=1.5)\n",
    "        edge_density = float(edges.mean())\n",
    "\n",
    "        # Grayscale histogram\n",
    "        hist, _ = np.histogram((gray * 255.0).astype(np.uint8), bins=hist_bins, range=(0, 255))\n",
    "        hist = hist.astype(np.float32)\n",
    "        hist = hist / (hist.sum() + 1e-9)\n",
    "\n",
    "        feats = {\n",
    "            \"width\": width, \"height\": height, \"aspect_ratio\": aspect,\n",
    "            \"mean_r\": mean_r, \"mean_g\": mean_g, \"mean_b\": mean_b,\n",
    "            \"std_r\": std_r, \"std_g\": std_g, \"std_b\": std_b,\n",
    "            \"brightness\": brightness, \"contrast\": contrast,\n",
    "            \"edge_density\": edge_density,\n",
    "        }\n",
    "        for i, v in enumerate(hist):\n",
    "            feats[f\"hist_{i:02d}\"] = float(v)\n",
    "        return feats\n",
    "\n",
    "    except Exception as e:\n",
    "        base = {\n",
    "            \"width\": np.nan, \"height\": np.nan, \"aspect_ratio\": np.nan,\n",
    "            \"mean_r\": np.nan, \"mean_g\": np.nan, \"mean_b\": np.nan,\n",
    "            \"std_r\": np.nan, \"std_g\": np.nan, \"std_b\": np.nan,\n",
    "            \"brightness\": np.nan, \"contrast\": np.nan,\n",
    "            \"edge_density\": np.nan,\n",
    "        }\n",
    "        for i in range(hist_bins):\n",
    "            base[f\"hist_{i:02d}\"] = np.nan\n",
    "        base[\"error\"] = str(e)\n",
    "        return base\n",
    "\n",
    "def scan_folder(root: Path, label: int, split_name: str) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    files = list_images(root)\n",
    "    for p in files:\n",
    "        feats = extract_features_one(p)\n",
    "        rows.append({\n",
    "            \"split\": split_name,\n",
    "            \"label\": int(label),  # real=0, fake=1\n",
    "            \"filename\": p.name,\n",
    "            \"abspath\": str(p.resolve()),\n",
    "            **feats\n",
    "        })\n",
    "    print(f\"[INFO] {split_name} | label={label}: {len(files)} images from {root}\")\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "def plot_confusion_heatmap(cm: np.ndarray, labels: list, title: str, out_path: Path):\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    im = plt.imshow(cm, aspect='equal')\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"True\")\n",
    "    plt.colorbar(im)\n",
    "    plt.xticks(range(len(labels)), labels)\n",
    "    plt.yticks(range(len(labels)), labels)\n",
    "    for (i, j), v in np.ndenumerate(cm):\n",
    "        plt.text(j, i, str(v), ha='center', va='center')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_path, dpi=220)\n",
    "    plt.close()\n",
    "\n",
    "# ----------------------------\n",
    "# 1) Load & Feature-ize datasets\n",
    "# ----------------------------\n",
    "train_real_df = scan_folder(TRAIN_REAL, label=0, split_name=\"train\")\n",
    "train_fake_df = scan_folder(TRAIN_FAKE, label=1, split_name=\"train\")\n",
    "test_real_df  = scan_folder(TEST_REAL,  label=0, split_name=\"test\")\n",
    "test_fake_df  = scan_folder(TEST_FAKE,  label=1, split_name=\"test\")\n",
    "\n",
    "dfs = [train_real_df, train_fake_df, test_real_df, test_fake_df]\n",
    "if SAMPLE_FAKE.exists():\n",
    "    sample_fake_df = scan_folder(SAMPLE_FAKE, label=1, split_name=\"sample\")\n",
    "    dfs.append(sample_fake_df)\n",
    "else:\n",
    "    sample_fake_df = pd.DataFrame()\n",
    "\n",
    "all_df = pd.concat([d for d in dfs if not d.empty], ignore_index=True)\n",
    "if all_df.empty:\n",
    "    raise SystemExit(\"No images found. Please check your paths.\")\n",
    "\n",
    "# Drop rows missing core features\n",
    "core = [\"width\",\"height\",\"aspect_ratio\",\"brightness\",\"contrast\",\"edge_density\"]\n",
    "all_df = all_df.dropna(subset=core).reset_index(drop=True)\n",
    "\n",
    "# Feature columns\n",
    "non_feat = {\"split\",\"label\",\"filename\",\"abspath\",\"error\"}\n",
    "feat_cols = [c for c in all_df.columns if c not in non_feat and pd.api.types.is_numeric_dtype(all_df[c])]\n",
    "\n",
    "# Train / Test (sample is extra)\n",
    "train_df = all_df[all_df[\"split\"] == \"train\"].copy()\n",
    "test_df  = all_df[all_df[\"split\"] == \"test\"].copy()\n",
    "has_sample = not sample_fake_df.empty\n",
    "if has_sample:\n",
    "    sample_df = all_df[all_df[\"split\"] == \"sample\"].copy()\n",
    "\n",
    "if train_df.empty or test_df.empty:\n",
    "    raise SystemExit(\"Train or Test split is empty. Ensure train/test folders have images.\")\n",
    "\n",
    "X_train = train_df[feat_cols].astype(float).values\n",
    "y_train = train_df[\"label\"].astype(int).values\n",
    "X_test  = test_df[feat_cols].astype(float).values\n",
    "y_test  = test_df[\"label\"].astype(int).values\n",
    "\n",
    "# ----------------------------\n",
    "# 2) Pipeline: Standardize + Balanced Logistic Regression\n",
    "# ----------------------------\n",
    "pipe = Pipeline(steps=[\n",
    "    (\"scaler\", StandardScaler(with_mean=True, with_std=True)),\n",
    "    (\"clf\", LogisticRegression(\n",
    "        solver=\"saga\",\n",
    "        penalty=\"l2\",\n",
    "        class_weight=\"balanced\",\n",
    "        max_iter=1000,\n",
    "        n_jobs=-1,\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "print(\"[INFO] Training model...\")\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "# ----------------------------\n",
    "# 3) Predict on Test (+ Sample)\n",
    "# ----------------------------\n",
    "# Test\n",
    "probs_test = pipe.predict_proba(X_test)[:, 1]\n",
    "preds_test = (probs_test >= THRESHOLD).astype(int)\n",
    "\n",
    "test_out = pd.DataFrame({\n",
    "    \"filename\": test_df[\"filename\"].values,\n",
    "    \"abspath\": test_df[\"abspath\"].values,\n",
    "    \"y_true\": y_test,\n",
    "    \"prob_fake\": probs_test,\n",
    "    \"y_pred\": preds_test\n",
    "})\n",
    "test_out.to_csv(TEST_PRED_CSV, index=False)\n",
    "print(f\"[SAVED] Test predictions -> {TEST_PRED_CSV}\")\n",
    "\n",
    "# Sample (if present; note: ground truth is fake=1 by construction)\n",
    "if has_sample:\n",
    "    X_sample = sample_df[feat_cols].astype(float).values\n",
    "    probs_sample = pipe.predict_proba(X_sample)[:, 1]\n",
    "    preds_sample = (probs_sample >= THRESHOLD).astype(int)\n",
    "    sample_out = pd.DataFrame({\n",
    "        \"filename\": sample_df[\"filename\"].values,\n",
    "        \"abspath\": sample_df[\"abspath\"].values,\n",
    "        \"prob_fake\": probs_sample,\n",
    "        \"y_pred\": preds_sample\n",
    "    })\n",
    "    sample_out.to_csv(SAMPLE_PRED_CSV, index=False)\n",
    "    print(f\"[SAVED] Sample predictions -> {SAMPLE_PRED_CSV}\")\n",
    "\n",
    "# ----------------------------\n",
    "# 4) Metrics & Plots (on Test set)\n",
    "# ----------------------------\n",
    "roc_auc = roc_auc_score(y_test, probs_test)\n",
    "pr_auc  = average_precision_score(y_test, probs_test)\n",
    "cm = confusion_matrix(y_test, preds_test, labels=[0,1])\n",
    "report = classification_report(y_test, preds_test, digits=4)\n",
    "\n",
    "print(f\"[INFO] Test ROC-AUC: {roc_auc:.4f} | PR-AUC: {pr_auc:.4f}\")\n",
    "print(\"[INFO] Confusion matrix:\\n\", cm)\n",
    "print(\"[INFO] Classification report:\\n\", report)\n",
    "\n",
    "# Save metrics json\n",
    "metrics = {\n",
    "    \"threshold\": THRESHOLD,\n",
    "    \"roc_auc\": float(roc_auc),\n",
    "    \"pr_auc\": float(pr_auc),\n",
    "    \"confusion_matrix\": {\n",
    "        \"tn\": int(cm[0,0]), \"fp\": int(cm[0,1]),\n",
    "        \"fn\": int(cm[1,0]), \"tp\": int(cm[1,1])\n",
    "    }\n",
    "}\n",
    "with open(METRICS_JSON, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(metrics, f, indent=2)\n",
    "print(f\"[SAVED] Metrics JSON -> {METRICS_JSON}\")\n",
    "\n",
    "# Save classification report\n",
    "with open(CLS_TXT, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"=== DeepFakeShield: Balanced Logistic Regression (Test) ===\\n\\n\")\n",
    "    f.write(report + \"\\n\")\n",
    "print(f\"[SAVED] Classification report -> {CLS_TXT}\")\n",
    "\n",
    "# ROC curve\n",
    "fpr, tpr, _ = roc_curve(y_test, probs_test)\n",
    "plt.figure(figsize=(6,5))\n",
    "plt.plot(fpr, tpr, label=f\"ROC-AUC={roc_auc:.3f}\")\n",
    "plt.plot([0,1],[0,1],\"--\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate (Recall)\")\n",
    "plt.title(\"DeepFakeShield: ROC Curve\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig(ROC_PNG, dpi=220)\n",
    "plt.close()\n",
    "print(f\"[SAVED] ROC curve -> {ROC_PNG}\")\n",
    "\n",
    "# PR curve\n",
    "prec, rec, _ = precision_recall_curve(y_test, probs_test)\n",
    "plt.figure(figsize=(6,5))\n",
    "plt.plot(rec, prec, label=f\"PR-AUC={pr_auc:.3f}\")\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.title(\"DeepFakeShield: Precision-Recall Curve\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig(PR_PNG, dpi=220)\n",
    "plt.close()\n",
    "print(f\"[SAVED] PR curve -> {PR_PNG}\")\n",
    "\n",
    "# Confusion matrix heatmap\n",
    "plt.figure(figsize=(5.2,4.6))\n",
    "im = plt.imshow(cm, aspect='equal')\n",
    "plt.title(f\"DeepFakeShield: Confusion Matrix (th={THRESHOLD})\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.colorbar(im)\n",
    "plt.xticks([0,1], [\"Real (0)\", \"Fake (1)\"])\n",
    "plt.yticks([0,1], [\"Real (0)\", \"Fake (1)\"])\n",
    "for (i, j), v in np.ndenumerate(cm):\n",
    "    plt.text(j, i, str(v), ha='center', va='center')\n",
    "plt.tight_layout()\n",
    "plt.savefig(CM_PNG, dpi=220)\n",
    "plt.close()\n",
    "print(f\"[SAVED] Confusion matrix -> {CM_PNG}\")\n",
    "\n",
    "# ----------------------------\n",
    "# 5) Feature importance (LogReg coefficients)\n",
    "# ----------------------------\n",
    "# Coefs correspond to standardized features\n",
    "clf = pipe.named_steps[\"clf\"]\n",
    "if hasattr(clf, \"coef_\"):\n",
    "    coefs = clf.coef_.ravel()\n",
    "    fi = pd.DataFrame({\n",
    "        \"feature\": feat_cols,\n",
    "        \"coef\": coefs,\n",
    "        \"importance_abs\": np.abs(coefs)\n",
    "    }).sort_values(\"importance_abs\", ascending=False)\n",
    "    fi.to_csv(FI_CSV, index=False)\n",
    "    print(f\"[SAVED] Feature importance -> {FI_CSV}\")\n",
    "\n",
    "# ----------------------------\n",
    "# 6) Save trained model\n",
    "# ----------------------------\n",
    "joblib.dump(pipe, MODEL_PKL)\n",
    "print(f\"[SAVED] Model -> {MODEL_PKL}\")\n",
    "\n",
    "print(\"\\n[DONE] All artifacts saved in:\", OUT_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef695b94-63ad-4b0e-9642-2d51ca6ef056",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (moviepy)",
   "language": "python",
   "name": "py311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
